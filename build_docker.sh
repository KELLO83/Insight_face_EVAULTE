#!/bin/bash

echo "ğŸš€ ë„ì»¤ ì´ë¯¸ì§€ ë¹Œë“œ ì‹œì‘..."
echo "================================================"
echo "ğŸ“‹ ë¹Œë“œ í™˜ê²½ :"
echo "   - Base Image: pytorch/pytorch:2.7.1-cuda12.6-cudnn9-devel"
echo "   - Python: 3.10.12"
echo "   - PyTorch: 2.7.1+cu126"
echo "   - CUDA: 12.6"
echo "   - cuDNN: 9.x"
echo "   - ONNX Runtime GPU: 1.22.0"
echo "   - InsightFace: 0.7.3"
echo ""

docker build -t insightface-gpu:cuda12.6-py310 .

if [ $? -eq 0 ]; then
    echo "âœ… ë„ì»¤ ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ!"
    echo ""
    echo "ğŸ“‹ ì‚¬ìš©ë²•:"
    echo "1. ë‹¨ì¼ ì‹¤í–‰:"
    echo "   docker run --gpus all -v \$(pwd)/models:/app/models -v \$(pwd)/man:/app/man insightface-gpu:cuda12.6-py310"
    echo ""
    echo "2. ëŒ€í™”í˜• ëª¨ë“œ:"
    echo "   docker run --gpus all -it -v \$(pwd)/models:/app/models -v \$(pwd)/man:/app/man insightface-gpu:cuda12.6-py310 bash"
    echo ""
    echo "3. ë°ì´í„°ì…‹ í‰ê°€:"
    echo "   docker run --gpus all -v \$(pwd)/models:/app/models -v \$(pwd)/pair:/app/pair insightface-gpu:cuda12.6-py310 python single_insightface.py --model_name antelopev2"
    echo ""
    echo "4. Docker Compose ì‚¬ìš©:"
    echo "   docker-compose up"
    echo ""
    echo "ğŸ”„ ì´ë¯¸ì§€ ì •ë³´:"
    docker images insightface-gpu:cuda12.6-py310
    echo ""
    echo "ğŸ§ª í™˜ê²½ ê²€ì¦ ì¤‘..."
    echo "================================================"
    
    # ìë™ í™˜ê²½ ê²€ì¦ ì‹¤í–‰
    docker run --gpus all --rm insightface-gpu:cuda12.6-py310 python -c "
import torch
import onnxruntime as ort
print('âœ… í™˜ê²½ ê²€ì¦ ê²°ê³¼:')
print(f'   - PyTorch: {torch.__version__}')
print(f'   - CUDA available: {torch.cuda.is_available()}')
print(f'   - CUDA version: {torch.version.cuda}')
print(f'   - GPU count: {torch.cuda.device_count()}')
print(f'   - ONNX Runtime providers: {ort.get_available_providers()[:2]}')
print('ğŸ‰ Docker í™˜ê²½ ì¤€ë¹„ ì™„ë£Œ!')
"
    
    echo ""
    echo "ğŸ“‹ ì‹¤í–‰ ë°©ë²•:"
    echo "   ./run_docker.sh buffalo_l    # Buffalo-L ëª¨ë¸"
    echo "   ./run_docker.sh antelopev2   # Antelope v2 ëª¨ë¸"
    echo "   ./run_docker.sh buffalo_s    # Buffalo-S ëª¨ë¸ (ê²½ëŸ‰)"
else
    echo "âŒ ë„ì»¤ ì´ë¯¸ì§€ ë¹Œë“œ ì‹¤íŒ¨!"
    echo ""
    echo "ğŸ” ë¬¸ì œ í•´ê²°:"
    echo "1. NVIDIA Container Toolkit ì„¤ì¹˜ í™•ì¸: docker run --rm --gpus all nvidia/cuda:12.6-base-ubuntu22.04 nvidia-smi"
    echo "2. Docker ê·¸ë£¹ ê¶Œí•œ í™•ì¸: groups \$USER"
    echo "3. ë¡œê·¸ í™•ì¸: docker logs <container_id>"
    exit 1
fi
