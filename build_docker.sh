#!/bin/bash

echo "ğŸš€ InsightFace GPU ë„ì»¤ ì´ë¯¸ì§€ ë¹Œë“œ ì‹œì‘..."
echo "================================================"
echo "ğŸ“‹ ë¹Œë“œ í™˜ê²½ (ë¡œì»¬ .venvì™€ ë™ì¼):"
echo "   - Base Image: pytorch/pytorch:2.7.1-cuda12.6-cudnn9-devel"
echo "   - Python: 3.10.12"
echo "   - PyTorch: 2.7.1+cu126"
echo "   - CUDA: 12.6"
echo "   - cuDNN: 9.x"
echo "   - ONNX Runtime GPU: 1.22.0"
echo "   - InsightFace: 0.7.3"
echo ""

# ë„ì»¤ ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t insightface-gpu:cuda12.6-py310 .

if [ $? -eq 0 ]; then
    echo "âœ… ë„ì»¤ ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ!"
    echo ""
    echo "ğŸ“‹ ì‚¬ìš©ë²•:"
    echo "1. ë‹¨ì¼ ì‹¤í–‰:"
    echo "   docker run --gpus all -v \$(pwd)/models:/app/models -v \$(pwd)/man:/app/man insightface-gpu:cuda12.6-py310"
    echo ""
    echo "2. ëŒ€í™”í˜• ëª¨ë“œ:"
    echo "   docker run --gpus all -it -v \$(pwd)/models:/app/models -v \$(pwd)/man:/app/man insightface-gpu:cuda12.6-py310 bash"
    echo ""
    echo "3. ë°ì´í„°ì…‹ í‰ê°€:"
    echo "   docker run --gpus all -v \$(pwd)/models:/app/models -v \$(pwd)/pair:/app/pair insightface-gpu:cuda12.6-py310 python single_insightface.py --model_name antelopev2"
    echo ""
    echo "4. Docker Compose ì‚¬ìš©:"
    echo "   docker-compose up"
    echo ""
    echo "ğŸ”„ ì´ë¯¸ì§€ ì •ë³´:"
    docker images insightface-gpu:cuda12.6-py310
    echo ""
    echo "ğŸ§ª í™˜ê²½ ê²€ì¦ ëª…ë ¹ì–´:"
    echo "docker run --gpus all --rm insightface-gpu:cuda12.6-py310 python -c \\"
    echo "  import torch, onnxruntime as ort; \\"
    echo "  print(f'PyTorch: {torch.__version__}'); \\"
    echo "  print(f'CUDA available: {torch.cuda.is_available()}'); \\"
    echo "  print(f'CUDA version: {torch.version.cuda}'); \\"
    echo "  print(f'ONNX Runtime providers: {ort.get_available_providers()}'); \\"
    echo "  print(f'GPU count: {torch.cuda.device_count()}')\\"
else
    echo "âŒ ë„ì»¤ ì´ë¯¸ì§€ ë¹Œë“œ ì‹¤íŒ¨!"
    echo ""
    echo "ğŸ” ë¬¸ì œ í•´ê²°:"
    echo "1. NVIDIA Container Toolkit ì„¤ì¹˜ í™•ì¸: docker run --rm --gpus all nvidia/cuda:12.6-base-ubuntu22.04 nvidia-smi"
    echo "2. Docker ê·¸ë£¹ ê¶Œí•œ í™•ì¸: groups \$USER"
    echo "3. ë¡œê·¸ í™•ì¸: docker logs <container_id>"
    exit 1
fi
